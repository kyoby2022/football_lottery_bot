import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import sqlite3
from datetime import datetime
from betting_processor import BettingProcessor

# --- é…ç½®åŒº ---
DB_NAME = "football_lottery.db"
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

# --- æ•°æ®åº“é€»è¾‘ ---
def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
    conn = sqlite3.connect(DB_NAME)
    cursor = conn.cursor()
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS sfc_matches (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            period TEXT,
            match_no TEXT,
            league TEXT,
            match_time TEXT,
            home_team TEXT,
            away_team TEXT,
            odds_win TEXT,
            odds_draw TEXT,
            odds_loss TEXT,
            handicap TEXT,
            scrape_time DATETIME
        )
    ''')
    conn.commit()
    conn.close()

def get_handicap_prob(handicap_text):
    # 1. ç›˜å£è½¬æ•°å­—æ˜ å°„
    mapping = {
        "å¹³æ‰‹": 0.0, "å¹³/åŠ": 0.25, "åŠçƒ": 0.5, "åŠ/ä¸€": 0.75,
        "ä¸€çƒ": 1.0, "ä¸€/çƒåŠ": 1.25, "çƒåŠ": 1.5, "çƒåŠ/ä¸¤": 1.75
    }
    h_value = mapping.get(handicap_text, 0.0)
    
    # 2. ç›˜å£è½¬åŸºå‡†æ¦‚ç‡ (ç®€åŒ–çº¿æ€§æ¨¡å‹ï¼š0.5è®©çƒå¯¹åº”50%èƒœç‡)
    # åŸºç¡€å…¬å¼ï¼šèƒœç‡ = 0.38 (å¹³æ‰‹åŸºå‡†) + è®©çƒæ•° * 0.25
    # è¿™æ˜¯ä¸€ä¸ªç»éªŒå…¬å¼ï¼Œå¯ä»¥æ ¹æ®åç»­Agentå¤ç›˜ä¸æ–­ä¿®æ­£
    implied_prob = 0.38 + (h_value * 0.24)
    return min(implied_prob, 0.95) # æœ€é«˜ä¸è¶…è¿‡95%

def calculate_synthetic_prob(win_odds, draw_odds, loss_odds, handicap_text):
    # è®¡ç®—æ¬§æŒ‡å»æŠ½æ°´èƒœç‡ (Pe)
    p_w = 1 / float(win_odds)
    p_d = 1 / float(draw_odds)
    p_l = 1 / float(loss_odds)
    pe_win = p_w / (p_w + p_d + p_l)
    
    # è®¡ç®—ç›˜å£éšå«èƒœç‡ (Ph)
    ph_win = get_handicap_prob(handicap_text)
    
    # æœ€ç»ˆåˆæˆï¼š60%æ¬§æŒ‡æƒé‡ + 40%ç›˜å£æƒé‡
    final_win_prob = (pe_win * 0.6) + (ph_win * 0.4)
    return round(final_win_prob * 100, 2)

def save_to_sqlite(df, period):
    """å°†æ•°æ®ä¿å­˜è‡³SQLiteï¼Œé¿å…é‡å¤å†™å…¥åŒä¸€æœŸ"""
    conn = sqlite3.connect(DB_NAME)
    # å…ˆåˆ é™¤è¯¥æœŸæ—§æ•°æ®ï¼ˆé˜²æ­¢é‡å¤æŠ“å–å¯¼è‡´æ•°æ®å †ç§¯ï¼‰
    conn.execute("DELETE FROM sfc_matches WHERE period = ?", (period,))
    df.to_sql('sfc_matches', conn, if_exists='append', index=False)
    conn.close()

# --- æŠ“å–é€»è¾‘ ---
def fetch_data():
    """ä»500ç½‘æŠ“å–æœ€æ–°å¯¹é˜µå’Œèµ”ç‡"""
    url = "https://trade.500.com/sfc/"
    res = requests.get(url, headers=HEADERS)
    res.encoding = 'gbk'
    soup = BeautifulSoup(res.text, 'lxml')
    
    # --- 1. æŠ“å–æˆªæ­¢æ—¶é—´ (ä¸å­˜åº“) ---
    deadline = "æœªçŸ¥"
    endtime_element = soup.select_one('.zcfilter-endtime')
    if endtime_element:
        # æå– "01-29 22:00" éƒ¨åˆ†
        deadline = endtime_element.text.replace("å®˜æ–¹å”®å½©æˆªæ­¢æ—¶é—´ï¼š", "").strip()

    # è‡ªåŠ¨è·å–å½“å‰æœŸå·
    # å®šä½åˆ° class ä¸º chked çš„ li æ ‡ç­¾
    period_element = soup.select_one('.qih-list li.chked')
    if period_element:
        # ä¼˜å…ˆè·å– data-expect å±æ€§ï¼Œè¿™é€šå¸¸æ˜¯çº¯æ•°å­—æœŸå·ï¼ˆå¦‚ 26020ï¼‰
        period = period_element.get('data-expect', "").strip()
        
        # å¦‚æœæ²¡å–åˆ°å±æ€§ï¼Œå†é™çº§å°è¯•è§£ææ–‡å­—
        if not period:
            period = period_element.text.replace("å½“å‰ç¬¬", "").replace("æœŸ", "").strip()
    else:
        period = "æœªçŸ¥æœŸå·"
    
    match_rows = soup.select('tr[data-vs]')
    data_list = []
    
    for row in match_rows[:14]:
        tds = row.find_all('td')
        bjpl = row.get('data-bjpl', "").split(',')
        asian = row.get('data-asian', "").split(',')
        
        item = {
            "period": period,
            "match_no": tds[0].text.strip(),
            "league": tds[1].text.strip(),
            "match_time": tds[2].text.strip(),
            "home_team": row.select_one('.team-l a').text.strip() if row.select_one('.team-l a') else "æœªçŸ¥",
            "away_team": row.select_one('.team-r a').text.strip() if row.select_one('.team-r a') else "æœªçŸ¥",
            "odds_win": bjpl[0] if len(bjpl)>0 else "",
            "odds_draw": bjpl[1] if len(bjpl)>1 else "",
            "odds_loss": bjpl[2] if len(bjpl)>2 else "",
            "handicap": asian[1] if len(asian)>1 else "",
            "scrape_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        data_list.append(item)
    
    return pd.DataFrame(data_list), period,deadline

def get_analyzed_df(period):
    # æ­¥éª¤ 1ï¼šä» SQLite æ•°æ®åº“è¯»å–åŸå§‹æ•°æ®
    conn = sqlite3.connect("football_lottery.db")
    query = "SELECT * FROM sfc_matches WHERE period = ?"
    raw_df = pd.read_sql(query, conn, params=(period,))
    conn.close()

    if raw_df.empty:
        return None

    # æ­¥éª¤ 2ï¼šå®ä¾‹åŒ–ä½ çš„å¤„ç†å™¨
    proc = BettingProcessor()

    # æ­¥éª¤ 3ï¼šåŠ å·¥æ•°æ®ï¼ˆè¿™ä¸€æ­¥ä¼šç”Ÿæˆ èƒœ%ã€å¹³%ã€è´Ÿ% ç­‰åˆ—ï¼‰
    # è¿™å°±æ˜¯ select_9_final_logic æ‰€éœ€è¦çš„å…¥å‚
    analyzed_df = proc.process_dataframe(raw_df)
    
    return analyzed_df

def display_recommendation(final_9, total_p):
    st.markdown(f"### ğŸ† æ™ºèƒ½ä¼˜åŒ–æ–¹æ¡ˆ (å…¨ä¸­æ¦‚ç‡: **{total_p}%**)")

    # å®šä¹‰é«˜äº®å‡½æ•°
    def highlight_picks(row):
        # åˆå§‹åŒ–æ ·å¼ï¼šé»˜è®¤æ— è‰²
        styles = [''] * len(row)
        # è·å–å„åˆ—ç´¢å¼•
        cols = list(row.index)
        win_idx, draw_idx, loss_idx = cols.index('èƒœ%'), cols.index('å¹³%'), cols.index('è´Ÿ%')
        
        pick = str(row['å»ºè®®']) # å¦‚ "3" æˆ– "3/1"
        
        # ç»¿è‰²é«˜äº®çš„ CSS
        highlight_css = 'background-color: #27ae60; color: white; font-weight: bold;'
        
        if "3" in pick: styles[win_idx] = highlight_css
        if "1" in pick: styles[draw_idx] = highlight_css
        if "0" in pick: styles[loss_idx] = highlight_css
        
        return styles

    # é€‰æ‹©éœ€è¦æ˜¾ç¤ºçš„åˆ—
    display_df = final_9[['match_no', 'home_team', 'away_team', 'èƒœ%', 'å¹³%', 'è´Ÿ%', 'å»ºè®®', 'æŠ•æ³•']]
    
    # åº”ç”¨æ ·å¼
    st.dataframe(
        display_df.style.apply(highlight_picks, axis=1),
        use_container_width=True,
        hide_index=True
    )

   


# --- Streamlit ç•Œé¢ ---
def main():
    st.set_page_config(page_title="è¶³å½©æ•°æ®çœ‹æ¿", layout="wide")
    st.title("âš½ ä¼ ç»Ÿè¶³å½© 14 åœºå®æ—¶æ•°æ®ä¸­å¿ƒ")
    
    init_db()
    
    col1, col2 = st.columns([1, 3])
    deadline = "æœªçŸ¥"
    
    with col1:
        st.subheader("æ§åˆ¶é¢æ¿")
        if st.button("ğŸš€ æŠ“å–æœ€æ–°å¯¹é˜µ"):
            with st.spinner('æ­£åœ¨åŒæ­¥500ç½‘æ•°æ®...'):
                try:
                    df, period,deadline = fetch_data()
                    save_to_sqlite(df, period)
                    st.success(f"æœŸå· {period} å·²æˆåŠŸå…¥åº“ï¼")
                except Exception as e:
                    st.error(f"æŠ“å–å¤±è´¥: {e}")
        
        st.write("---")
        st.info("æç¤ºï¼šç‚¹å‡»æŒ‰é’®åï¼Œæ•°æ®å°†è‡ªåŠ¨ä¿å­˜è‡³æœ¬åœ° football_lottery.db æ–‡ä»¶ã€‚")

        st.subheader("å±é™©æ“ä½œ")
        if st.button("ğŸ—‘ï¸ æ¸…ç†æ‰€æœ‰æœªçŸ¥æœŸå·"):
            conn = sqlite3.connect(DB_NAME)
            cursor = conn.cursor()
            cursor.execute("DELETE FROM sfc_matches WHERE period = 'æœªçŸ¥æœŸå·'")
            count = cursor.rowcount
            conn.commit()
            conn.close()
            st.warning(f"å·²æ¸…ç† {count} æ¡è„æ•°æ®ï¼")
            st.rerun() # åˆ·æ–°ç½‘é¡µæŸ¥çœ‹æ•ˆæœ
       
           
           

    with col2:
        st.subheader("å½“å‰æ•°æ®å±•ç°")
        st.metric(label="â³ æœ¬æœŸè´­ä¹°æˆªæ­¢æ—¶é—´", value=deadline)
        conn = sqlite3.connect(DB_NAME)
        # ä»æ•°æ®åº“è¯»å–æ‰€æœ‰æŠ“å–è¿‡çš„ä¿¡æ¯
        all_data = pd.read_sql("SELECT * FROM sfc_matches ORDER BY scrape_time DESC", conn)
        
        
        if not all_data.empty:
            
            # å¢åŠ ä¸€ä¸ªç­›é€‰å™¨ï¼ŒæŸ¥çœ‹ä¸åŒæœŸå·
            periods = all_data['period'].unique()
            selected_period = st.selectbox("é€‰æ‹©è¦æŸ¥çœ‹çš„æœŸå·", periods)
            
            display_df = all_data[all_data['period'] == selected_period]
            st.table(display_df.drop(columns=['id', 'scrape_time'])) # éšè—å†…éƒ¨IDæ˜¾ç¤º
        else:
            st.warning("æ•°æ®åº“ç›®å‰ä¸ºç©ºï¼Œè¯·ç‚¹å‡»å·¦ä¾§æŒ‰é’®è¿›è¡Œç¬¬ä¸€æ¬¡æŠ“å–ã€‚")

        st.subheader("æ•°æ®åˆ†æçœ‹æ¿")
        # 1. ä»åº“é‡Œæ‹¿åŸå§‹æ•°æ®
        raw_df = pd.read_sql("SELECT * FROM sfc_matches WHERE period = ?", conn, params=(selected_period,))
        
        # 2. è°ƒç”¨ç‹¬ç«‹çš„å¤„ç†å™¨è¿›è¡Œè®¡ç®—
        proc = BettingProcessor()
        analyzed_df = proc.process_dataframe(raw_df)

        # å®šä¹‰é«˜äº®é€»è¾‘ï¼šæ¦‚ç‡æœ€å¤§çš„é‚£ä¸€é¡¹å˜ç»¿
        def highlight_max(s):
            is_max = s == s.max()
            return ['background-color: #1b5e20; color: white' if v else '' for v in is_max]

        st.dataframe(
            analyzed_df.style.apply(highlight_max, axis=1, subset=['èƒœ%', 'å¹³%', 'è´Ÿ%']),
            use_container_width=True
        )

        if st.button("ç”Ÿæˆæ™ºèƒ½æ¨è"):
            conn = sqlite3.connect(DB_NAME)
            # ä»æ•°æ®åº“è¯»å–æ‰€æœ‰æŠ“å–è¿‡çš„ä¿¡æ¯
            all_data = pd.read_sql("SELECT * FROM sfc_matches ORDER BY scrape_time DESC", conn)
            if not all_data.empty:
                # å¢åŠ ä¸€ä¸ªç­›é€‰å™¨ï¼ŒæŸ¥çœ‹ä¸åŒæœŸå·
                periods = all_data['period'].unique()
                # å˜é‡åœ¨è¿™é‡Œå®šä¹‰çš„
                selected_period = st.selectbox("é€‰æ‹©æœŸå·", periods) 
                df_for_logic = get_analyzed_df(selected_period)

                proc = BettingProcessor()
                
                if df_for_logic is not None:
                    # è°ƒç”¨ä½ çš„ç­›é€‰é€»è¾‘å‡½æ•°
                    final_9, total_p = proc.select_9_final_logic(df_for_logic)
                    
                    # B. è°ƒç”¨æ˜¾ç¤ºå‡½æ•°ï¼ˆæ¸²æŸ“é‡‘è‰²å¡ç‰‡å’Œé«˜äº®è¡¨æ ¼ï¼‰
                    display_recommendation(final_9, total_p)
                else:
                    st.error("è¯¥æœŸå·ä¸‹æš‚æ— æ•°æ®ï¼Œè¯·å…ˆæ‰§è¡ŒæŠ“å–ã€‚")
    
   

    

if __name__ == "__main__":
    main()